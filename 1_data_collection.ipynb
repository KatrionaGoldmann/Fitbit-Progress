{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Fitbit Data\n",
    "\n",
    "<b> Katriona Goldmann </b>\n",
    "\n",
    "\n",
    "This script accesses the fitbit API and outputs the data to csv files. Fitbit API Python Client Implemented using scripts by [Brad Pitcher's python-fitbit repo](https://github.com/orcasgit/python-fitbit). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "* [Step 1: Access the fitbit API](#first-bullet)\n",
    "* [Step 2: Extract the Data](#second-bullet)\n",
    "* [Step 3: Export Exercise Data](#exercise-bullet)\n",
    "* [Step 4: Export Daily Summaries](#summary-bullet)\n",
    "* [Step 5: Export the sleep summary data](#sleep-bullet)\n",
    "\n",
    "I have automated the script to replot the data every other day using [launchd](https://medium.com/@chetcorcos/a-simple-launchd-tutorial-9fecfcf2dbb3) on my laptop. There is also a copy of the launchd script, as well as the bash script it exectutes (fitbit-update.sh), in this repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Access the fitbit API <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "Import the necessary packages and their use cases for this project:\n",
    "   \n",
    ">fitbit: access fitbit data <br>\n",
    ">gather_keys_oauth2: authorize fitbit access <br>\n",
    ">pandas: data frames and data manipulation <br>\n",
    ">numpy: summary statistics <br>\n",
    ">datetime: turn the dates into datetime objects / get day of week <br>\n",
    ">cherrypy: for web applications<br>\n",
    ">sys: This module provides access to some variables used or maintained by the interpreter<br>\n",
    ">gather_keys_oauth: to authorize the API, script [here](https://github.com/orcasgit/python-fitbit/blob/master/gather_keys_oauth2.py)<br>\n",
    "\n",
    "To download the fitbit module simply run \n",
    "> $ pip install git+git://github.com/orcasgit/python-fitbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitbit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import cherrypy\n",
    "import sys\n",
    "import gather_keys_oauth2 as Oauth2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have saved my api keys in a csv file located within this directory. Your will need to enter your unique client ID and secret as described in step 1 [here](https://towardsdatascience.com/collect-your-own-fitbit-data-with-python-ff145fa10873):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Inputs/api_key.csv')\n",
    "\n",
    "CLIENT_ID = df.iat[0,0]\n",
    "CLIENT_SECRET = df.iat[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Oauth2.OAuth2Server(CLIENT_ID, CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will take you to a new tab for authentification, you may need to log in and approve. The tab can be closed once authorized. If this causes errors, this may be due to package versions installed (see [here](https://github.com/orcasgit/python-fitbit/issues/142)). If this is the case roll back to previous versions: pip install requests-oauthlib==1.1.0, and pip install oauthlib==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/Mar/2019:20:34:18] ENGINE Listening for SIGTERM.\n",
      "[05/Mar/2019:20:34:18] ENGINE Listening for SIGHUP.\n",
      "[05/Mar/2019:20:34:18] ENGINE Listening for SIGUSR1.\n",
      "[05/Mar/2019:20:34:18] ENGINE Bus STARTING\n",
      "CherryPy Checker:\n",
      "The Application mounted at '' has an empty config.\n",
      "\n",
      "[05/Mar/2019:20:34:18] ENGINE Started monitor thread 'Autoreloader'.\n",
      "[05/Mar/2019:20:34:18] ENGINE Serving on http://127.0.0.1:8080\n",
      "[05/Mar/2019:20:34:18] ENGINE Bus STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Mar/2019:20:34:21] \"GET /?code=b7f2b3345562f903d8dee626b8dce45d7a6fcdc3&state=KGhHwVN8jKVTzT6D24VUVAGEfhg0MR HTTP/1.1\" 200 122 \"\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/Mar/2019:20:34:22] ENGINE Bus STOPPING\n",
      "[05/Mar/2019:20:34:27] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('127.0.0.1', 8080)) shut down\n",
      "[05/Mar/2019:20:34:27] ENGINE Stopped thread 'Autoreloader'.\n",
      "[05/Mar/2019:20:34:27] ENGINE Bus STOPPED\n",
      "[05/Mar/2019:20:34:27] ENGINE Bus EXITING\n",
      "[05/Mar/2019:20:34:27] ENGINE Bus EXITED\n",
      "[05/Mar/2019:20:34:27] ENGINE Waiting for child threads to terminate...\n"
     ]
    }
   ],
   "source": [
    "server.browser_authorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = str(server.fitbit.client.session.token['access_token'])\n",
    "REFRESH_TOKEN = str(server.fitbit.client.session.token['refresh_token'])\n",
    "\n",
    "auth2_client = fitbit.Fitbit(\n",
    "    CLIENT_ID,\n",
    "    CLIENT_SECRET,\n",
    "    oauth2=True,\n",
    "    access_token=ACCESS_TOKEN,\n",
    "    refresh_token=REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Extract the User Data <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "The details and documentation for the API functions can be found [here](https://python-fitbit.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = auth2_client.user_profile_get()[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average daily steps:  10601 \n",
      "stride length:  0.648 m \n",
      "running stride length:  0.961 m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage daily steps: \", user_info[\"averageDailySteps\"], \n",
    "      \"\\nstride length: \", user_info[\"strideLengthWalking\"]*0.0254, 'm',\n",
    "      \"\\nrunning stride length: \", user_info[\"strideLengthRunning\"]*0.0254, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Export Exercise Data <a class=\"anchor\" id=\"exercise-bullet\"></a>\n",
    "\n",
    "\n",
    "Extract the log of exercise so that it can be analysed further down the line. This way we can monitor exercise frequncy and check for improvements or changes. But first lets check the dates we still need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of dates selected: -1 day, 0:00:00 from 2019-03-05 to 2019-03-04\n"
     ]
    }
   ],
   "source": [
    "# If the analysis has been run before, we only need to run from the last date\n",
    "if os.path.exists('./Outputs/exercise.csv'):\n",
    "    ex_comp = pd.read_csv('./Outputs/exercise.csv')\n",
    "    lastdate = ex_comp.iloc[-1]['lastModified'][0:10]\n",
    "else:\n",
    "    lastdate = \"2019/02/01\" # define the start date\n",
    "\n",
    "d1 = date(int(lastdate[0:4]), int(lastdate[5:7]), int(lastdate[8:10]))    # start date\n",
    "d2 = datetime.datetime.today().date() - timedelta(1) \n",
    "delta = (d2) - (d1) \n",
    "\n",
    "ex_dates_list = []\n",
    "for i in range(delta.days + 1): ex_dates_list.append(d1 + timedelta(i))\n",
    "\n",
    "print('Range of dates selected:', delta, 'from',  d1, 'to', d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'distance'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-11fe240dba79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mex_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance (miles)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance (miles)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.60934\u001b[0m  \u001b[0;31m# Convert to km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhD/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'distance'"
     ]
    }
   ],
   "source": [
    "ex_df = pd.DataFrame()\n",
    "\n",
    "for d in ex_dates_list:\n",
    "    summary = auth2_client.activities(date=d)\n",
    "    exercise = pd.DataFrame.from_records(summary['activities'])\n",
    "    ex_df = ex_df.append(exercise, sort=True)\n",
    "\n",
    "ex_df['distance (miles)'] = ex_df['distance']\n",
    "ex_df['distance'] = ex_df['distance (miles)'] * 1.60934  # Convert to km\n",
    "\n",
    "ex_df['startDate'] = [\n",
    "    datetime.datetime.strptime(x, '%Y-%m-%d').strftime('%d/%m/%Y')\n",
    "    for x in ex_df['startDate']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data frame and export it to a csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Outputs/exercise.csv', 'a') as f:\n",
    "    f.write('\\n') \n",
    "    ex_df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Export Daily Summaries <a class=\"anchor\" id=\"summary-bullet\"></a>\n",
    "\n",
    "Here we will export the summary of each day. This inlcudes minutes of activity, steps, calories and heart rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vars = ('Cardio (mins at HR)', 'Fat Burn (mins at HR)', 'Out of Range/low (mins at HR)', \\\n",
    "             'Peak (mins at HR)', 'caloriesOut', 'fairlyActiveMinutes', 'lightlyActiveMinutes', \\\n",
    "             'restingHeartRate', 'sedentaryMinutes', 'steps', 'veryActiveMinutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the analysis has been run before, we only need to run from the last date\n",
    "if os.path.exists('./Outputs/daily_summary.csv'):\n",
    "    ds_comp = pd.read_csv('./Outputs/daily_summary.csv')\n",
    "    lastdate = ds_comp.iloc[-1]['date'][0:10]\n",
    "else:\n",
    "    lastdate = \"2015/01/01\" # define the start date\n",
    "\n",
    "d1 = date(int(lastdate[6:10]), int(lastdate[3:5]), int(lastdate[0:2])) \n",
    "d2 = datetime.datetime.today().date() - timedelta(1) \n",
    "delta = (d2) - (d1) \n",
    "\n",
    "ds_dates_list = []\n",
    "for i in range(delta.days + 1): ds_dates_list.append(d1 + timedelta(i))\n",
    "\n",
    "print('Range of dates selected:', delta, 'from',  d1, 'to', d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.DataFrame()\n",
    "\n",
    "for d in ds_dates_list:\n",
    "    summary = auth2_client.activities(date=d)\n",
    "    daily_sum = {k: summary['summary'][k] for k in dict_vars if k in summary['summary'].keys()}\n",
    "    daily_sum2 = {k: 0 for k in dict_vars if k not in summary['summary'].keys()}\n",
    "    daily_sum.update(daily_sum2)\n",
    "\n",
    "    if 'heartRateZones' in summary['summary'].keys():\n",
    "        daily_sum['Out of Range/low (mins at HR)'] = summary['summary']['heartRateZones'][0]['minutes']\n",
    "        daily_sum['Fat Burn (mins at HR)'] = summary['summary']['heartRateZones'][1]['minutes']\n",
    "        daily_sum['Cardio (mins at HR)'] = summary['summary']['heartRateZones'][2]['minutes']\n",
    "        daily_sum['Peak (mins at HR)'] = summary['summary']['heartRateZones'][3]['minutes']\n",
    "    \n",
    "    daily_sum_df = pd.DataFrame.from_records(daily_sum, index=[0])\n",
    "    daily_df = daily_df.append(daily_sum_df, sort=True)\n",
    "    \n",
    "daily_df = daily_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_df.reindex(columns=dict_vars)\n",
    "daily_df['date'] = [x.strftime('%m/%d/%Y') for x in ds_dates_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect and export the daily summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Outputs/daily_summary.csv', 'a') as f:\n",
    "    f.write('\\n') \n",
    "    daily_df.to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Export Sleep Summary Data <a class=\"anchor\" id=\"sleep-bullet\"></a>\n",
    "\n",
    "Similarly we can export the sleep data which shows the hours in bed and hours asleep each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the analysis has been run before, we only need to run from the last date\n",
    "if os.path.exists('./Outputs/sleep_summary.csv'):\n",
    "    ss_comp = pd.read_csv('./Outputs/sleep_summary.csv')\n",
    "    lastdate= ss_comp.iloc[-1]['Date'][0:10]\n",
    "else:\n",
    "    lastdate = \"2015/01/01\" # define the start date\n",
    "\n",
    "print(lastdate)    \n",
    "\n",
    "d1 = date(int(lastdate[6:10]), int(lastdate[3:5]), int(lastdate[0:2]))     # start date\n",
    "d2 = datetime.datetime.today().date() - timedelta(1) \n",
    "delta = (d2) - (d1) \n",
    "\n",
    "ss_dates_list = []\n",
    "for i in range(delta.days + 1): ss_dates_list.append(d1 + timedelta(i))\n",
    "\n",
    "print('Range of dates selected:', delta, 'from',  d1, 'to', d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.DataFrame()\n",
    "\n",
    "for d in ss_dates_list:\n",
    "    fit_statsSl = auth2_client.sleep(date=d)\n",
    "    stime_list = []\n",
    "    sval_list = []\n",
    "\n",
    "    if len(fit_statsSl['sleep']) != 0:\n",
    "    \n",
    "        for i in fit_statsSl['sleep'][0]['minuteData']:\n",
    "            stime_list.append(i['dateTime'])\n",
    "            sval_list.append(i['value'])\n",
    "            \n",
    "        #Calculate the sleep summary\n",
    "        dict_sum = {\n",
    "            'Date' : d, \n",
    "            'Time in bed (mins)' : len(stime_list), \n",
    "            'Time asleep (mins)' : (sval_list.count('1')),\n",
    "            'Time awake (mins)' : (sval_list.count('2')),\n",
    "            'Time very awake (mins)' : (sval_list.count('3')),\n",
    "            'Bedtime (mins)' : (stime_list[0]),\n",
    "            'Wake up (mins)' : (stime_list[-1]),\n",
    "            'Total time' : \"{:.2f}\".format(((datetime.datetime.strptime(stime_list[-1],'%H:%M:%S') - \\\n",
    "                            datetime.datetime.strptime(stime_list[0],'%H:%M:%S')).total_seconds())/(60*60))\n",
    "        }\n",
    "\n",
    "        sleep_sum_df = pd.DataFrame.from_records(dict_sum, index=[0])\n",
    "        sleep_df = sleep_df.append(sleep_sum_df)\n",
    "    \n",
    "    else:\n",
    "        print('\\tNo sleep data for ' + d.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df['Date'] = [x.strftime('%m/%d/%Y') for x in sleep_df['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Outputs/sleep_summary.csv', 'a') as f:\n",
    "    f.write('\\n') \n",
    "    sleep_df.to_csv(f, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.3333435058594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
